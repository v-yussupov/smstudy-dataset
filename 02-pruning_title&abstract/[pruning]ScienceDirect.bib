% Encoding: UTF-8

@Article{GIMENEZALVENTOSA2019259,
  author   = {V. Giménez-Alventosa and Germán Moltó and Miguel Caballer},
  title    = {A framework and a performance assessment for serverless MapReduce on AWS Lambda},
  journal  = {Future Generation Computer Systems},
  year     = {2019},
  volume   = {97},
  pages    = {259 - 274},
  issn     = {0167-739X},
  abstract = {MapReduce is one of the most widely used programming models for analysing large-scale datasets, i.e. Big Data. In recent years, serverless computing and, in particular, Functions as a Service (FaaS) has surged as an execution model in which no explicit management of servers (e.g. virtual machines) is performed by the user. Instead, the Cloud provider dynamically allocates resources to the function invocations and fine-grained billing is introduced depending on the execution time and allocated memory, as exemplified by AWS Lambda. In this article, a high-performant serverless architecture has been created to execute MapReduce jobs on AWS Lambda using Amazon S3 as the storage backend. In addition, a thorough assessment has been carried out to study the suitability of AWS Lambda as a platform for the execution of High Throughput Computing jobs. The results indicate that AWS Lambda provides a convenient computing platform for general-purpose applications that fit within the constraints of the service (15 min of maximum execution time, 3008 MB of RAM and 512 MB of disk space) but it exhibits an inhomogeneous performance behaviour that may jeopardise adoption for tightly coupled computing jobs.},
  doi      = {https://doi.org/10.1016/j.future.2019.02.057},
  keywords = {MapReduce, Serverless, Cloud computing, Elasticity},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X18325172},
}

@Article{LEITNER2019340,
  author   = {Philipp Leitner and Erik Wittern and Josef Spillner and Waldemar Hummer},
  title    = {A mixed-method empirical study of Function-as-a-Service software development in industrial practice},
  journal  = {Journal of Systems and Software},
  year     = {2019},
  volume   = {149},
  pages    = {340 - 359},
  issn     = {0164-1212},
  abstract = {Function-as-a-Service (FaaS) describes cloud computing services that make infrastructure components transparent to application developers, thus falling in the larger group of “serverless” computing models. When using FaaS offerings, such as AWS Lambda, developers provide atomic and short-running code for their functions, and FaaS providers execute and horizontally scale them on-demand. Currently, there is no systematic research on how developers use serverless, what types of applications lend themselves to this model, or what architectural styles and practices FaaS-based applications are based on. We present results from a mixed-method study, combining interviews with practitioners who develop applications and systems that use FaaS, a systematic analysis of grey literature, and a Web-based survey. We find that successfully adopting FaaS requires a different mental model, where systems are primarily constructed by composing pre-existing services, with FaaS often acting as the “glue” that brings these services together. Tooling availability and maturity, especially related to testing and deployment, remains a major difficulty. Further, we find that current FaaS systems lack systematic support for function reuse, and abstractions and programming models for building non-trivial FaaS applications are limited. We conclude with a discussion of implications for FaaS providers, software developers, and researchers.},
  doi      = {https://doi.org/10.1016/j.jss.2018.12.013},
  keywords = {Cloud computing, Serverless, Function-as-a-Service, Empirical research},
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121218302735},
}

@Article{MALAWSKI2017,
  author   = {Maciej Malawski and Adam Gajek and Adam Zima and Bartosz Balis and Kamil Figiela},
  title    = {Serverless execution of scientific workflows: Experiments with HyperFlow, AWS Lambda and Google Cloud Functions},
  journal  = {Future Generation Computer Systems},
  year     = {2017},
  issn     = {0167-739X},
  abstract = {Scientific workflows consisting of a high number of interdependent tasks represent an important class of complex scientific applications. Recently, a new type of serverless infrastructures has emerged, represented by such services as Google Cloud Functions and AWS Lambda, also referred to as the Function-as-a-Service model. In this paper we take a look at such serverless infrastructures, which are designed mainly for processing background tasks of Web and Internet of Things applications, or event-driven stream processing. We evaluate their applicability to more compute- and data-intensive scientific workflows and discuss possible ways to repurpose serverless architectures for execution of scientific workflows. We have developed prototype workflow executor functions using AWS Lambda and Google Cloud Functions, coupled with the HyperFlow workflow engine. These functions can run workflow tasks in AWS and Google infrastructures, and feature such capabilities as data staging to/from S3 or Google Cloud Storage and execution of custom application binaries. We have successfully deployed and executed the Montage astronomy workflow, often used as a benchmark, and we report on initial results of its performance evaluation. Our findings indicate that the simple mode of operation makes this approach easy to use, although there are costs involved in preparing portable application binaries for execution in a remote environment. While our solution is an early prototype, we find the presented approach highly promising. We also discuss possible future steps related to execution of scientific workflows in serverless infrastructures. Finally, we perform a cost analysis and discuss implications with regard to resource management for scientific applications in general.},
  doi      = {https://doi.org/10.1016/j.future.2017.10.029},
  keywords = {Scientific workflows, Cloud functions, Serverless architectures, FaaS},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X1730047X},
}

@Article{PEREZ201850,
  author   = {Alfonso Pérez and Germán Moltó and Miguel Caballer and Amanda Calatrava},
  title    = {Serverless computing for container-based architectures},
  journal  = {Future Generation Computer Systems},
  year     = {2018},
  volume   = {83},
  pages    = {50 - 59},
  issn     = {0167-739X},
  abstract = {New architectural patterns (e.g. microservices), the massive adoption of Linux containers (e.g. Docker containers), and improvements in key features of Cloud computing such as auto-scaling, have helped developers to decouple complex and monolithic systems into smaller stateless services. In turn, Cloud providers have introduced serverless computing, where applications can be defined as a workflow of event-triggered functions. However, serverless services, such as AWS Lambda, impose serious restrictions for these applications (e.g. using a predefined set of programming languages or difficulting the installation and deployment of external libraries). This paper addresses such issues by introducing a framework and a methodology to create Serverless Container-aware ARchitectures (SCAR). The SCAR framework can be used to create highly-parallel event-driven serverless applications that run on customized runtime environments defined as Docker images on top of AWS Lambda. This paper describes the architecture of SCAR together with the cache-based optimizations applied to minimize cost, exemplified on a massive image processing use case. The results show that, by means of SCAR, AWS Lambda becomes a convenient platform for High Throughput Computing, specially for highly-parallel bursty workloads of short stateless jobs.},
  doi      = {https://doi.org/10.1016/j.future.2018.01.022},
  keywords = {Cloud computing, Serverless, Docker, Elasticity, AWS lambda},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X17316485},
}

@Article{SOLTANI2018121,
  author   = {Boubaker Soltani and Afifa Ghenai and Nadia Zeghib},
  title    = {Towards Distributed Containerized Serverless Architecture in Multi Cloud Environment},
  journal  = {Procedia Computer Science},
  year     = {2018},
  volume   = {134},
  pages    = {121 - 128},
  issn     = {1877-0509},
  note     = {The 15th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2018) / The 13th International Conference on Future Networks and Communications (FNC-2018) / Affiliated Workshops},
  abstract = {Compared to the traditional Cloud solution which consists of hiring resources from a single Cloud provider, Multi Cloud is a rather more efficient solution; because it combines the diverse benefits from them, thus, the different platforms complement each other on behalf the client applications. Moreover, Serverless Function technology is a powerful Cloud tool that hides the unnecessary infrastructure management details, hence, allowing the developers to solely focus on their own functional code. Nevertheless, as far as we found, Serverless Functions are always limited to the provider offering them and they are not adopted in a Multi Cloud context. In this paper, we tackled this limit by suggesting a distributed architecture which extends the Serverless technology advantages to a wider scope, permitting the client to get at time the Multi Cloud and Serverless strengths.},
  doi      = {https://doi.org/10.1016/j.procs.2018.07.152},
  keywords = {Multi Cloud, Serverless architecture, Peer to Peer, container, container cluster manager},
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050918311153},
}

@Article{TOPPER20185,
  author   = {Jon Topper},
  title    = {Compliance is not security},
  journal  = {Computer Fraud \& Security},
  year     = {2018},
  volume   = {2018},
  number   = {3},
  pages    = {5 - 8},
  issn     = {1361-3723},
  abstract = {Modern IT infrastructure practice is evolving at an incredible pace, with the ongoing proliferation of cloud computing, container orchestration platforms and, most recently, a trend that we're calling ‘serverless’. Is our security practice evolving along with it? IT infrastructure practice is evolving at an incredible pace, with the ongoing proliferation of cloud computing, container orchestration platforms and, most recently, the ‘serverless’ trend. But is our security practice evolving along with it? It's no longer sufficient, if indeed it ever was, to uncritically import a bunch of ‘best practices’ into your organisation once and then call that your security policy. Policies must evolve over time, with people at all levels of the business involved in their implementation, explains Jon Topper of The Scale Factory.},
  doi      = {https://doi.org/10.1016/S1361-3723(18)30022-8},
  url      = {http://www.sciencedirect.com/science/article/pii/S1361372318300228},
}

@Article{VAQUERO201920,
  author   = {Luis M. Vaquero and Felix Cuadrado and Yehia Elkhatib and Jorge Bernal-Bernabe and Satish N. Srirama and Mohamed Faten Zhani},
  title    = {Research challenges in nextgen service orchestration},
  journal  = {Future Generation Computer Systems},
  year     = {2019},
  volume   = {90},
  pages    = {20 - 38},
  issn     = {0167-739X},
  abstract = {Fog/edge computing, function as a service, and programmable infrastructures, like software-defined networking or network function virtualisation, are becoming ubiquitously used in modern Information Technology infrastructures. These technologies change the characteristics and capabilities of the underlying computational substrate where services run (e.g. higher volatility, scarcer computational power, or programmability). As a consequence, the nature of the services that can be run on them changes too (smaller codebases, more fragmented state, etc.). These changes bring new requirements for service orchestrators, which need to evolve so as to support new scenarios where a close interaction between service and infrastructure becomes essential to deliver a seamless user experience. Here, we present the challenges brought forward by this new breed of technologies and where current orchestration techniques stand with regards to the new challenges. We also present a set of promising technologies that can help tame this brave new world.},
  doi      = {https://doi.org/10.1016/j.future.2018.07.039},
  keywords = {NVM, SDN, NFV, Orchestration, Large scale, Serverless, FaaS, Churn, Edge, Fog},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X18303157},
}

@Article{VARGHESE2018849,
  author   = {Blesson Varghese and Rajkumar Buyya},
  title    = {Next generation cloud computing: New trends and research directions},
  journal  = {Future Generation Computer Systems},
  year     = {2018},
  volume   = {79},
  pages    = {849 - 861},
  issn     = {0167-739X},
  abstract = {The landscape of cloud computing has significantly changed over the last decade. Not only have more providers and service offerings crowded the space, but also cloud infrastructure that was traditionally limited to single provider data centers is now evolving. In this paper, we firstly discuss the changing cloud infrastructure and consider the use of infrastructure from multiple providers and the benefit of decentralising computing away from data centers. These trends have resulted in the need for a variety of new computing architectures that will be offered by future cloud infrastructure. These architectures are anticipated to impact areas, such as connecting people and devices, data-intensive computing, the service space and self-learning systems. Finally, we lay out a roadmap of challenges that will need to be addressed for realising the potential of next generation cloud systems.},
  doi      = {https://doi.org/10.1016/j.future.2017.09.020},
  keywords = {Cloud computing, Fog computing, Cloudlet, Multi-cloud, Serverless computing, Cloud security},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X17302224},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: saveOrderConfig:specified;author;false;abstract;false;abstract;false;}
