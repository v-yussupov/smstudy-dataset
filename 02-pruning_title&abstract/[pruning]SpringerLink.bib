% Encoding: UTF-8

@InProceedings{10.1007/978-3-319-99819-0_11,
author="Back, Timon
and Andrikopoulos, Vasilios",
editor="Kritikos, Kyriakos
and Plebani, Pierluigi 
and de Paoli, Flavio",
title="Using a Microbenchmark to Compare Function as a Service Solutions",
booktitle="Service-Oriented and Cloud Computing",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="146--160",
abstract="The Function as a Service (FaaS) subtype of serverless computing provides the means for abstracting away from servers on which developed software is meant to be executed. It essentially offers an event-driven and scalable environment in which billing is based on the invocation of functions and not on the provisioning of resources. This makes it very attractive for many classes of applications with bursty workload. However, the terms under which FaaS services are structured and offered to consumers uses mechanisms like GB--seconds (that is, X GigaBytes of memory used for Y seconds of execution) that differ from the usual models for compute resources in cloud computing. Aiming to clarify these terms, in this work we develop a microbenchmark that we use to evaluate the performance and cost model of popular FaaS solutions using well known algorithmic tasks. The results of this process show a field still very much under development, and justify the need for further extensive benchmarking of these services.",
isbn="978-3-319-99819-0"
}

@Inbook{Baldini2017,
author="Baldini, Ioana
and Castro, Paul
and Chang, Kerry
and Cheng, Perry
and Fink, Stephen
and Ishakian, Vatche
and Mitchell, Nick
and Muthusamy, Vinod
and Rabbah, Rodric
and Slominski, Aleksander
and Suter, Philippe",
editor="Chaudhary, Sanjay
and Somani, Gaurav
and Buyya, Rajkumar",
title="Serverless Computing: Current Trends and Open Problems",
bookTitle="Research Advances in Cloud Computing",
year="2017",
publisher="Springer Singapore",
address="Singapore",
pages="1--20",
abstract="Serverless computing has emerged as a new compelling paradigm for the deployment of applications and services. It represents an evolution of cloud programming models, abstractions, and platforms, and is a testament to the maturity and wide adoption of cloud technologies. In this chapter, we survey existing serverless platforms from industry, academia, and open-source projects, identify key characteristics and use cases, and describe technical challenges and open problems.",
isbn="978-981-10-5026-8",
doi="10.1007/978-981-10-5026-8_1",
url="https://doi.org/10.1007/978-981-10-5026-8_1"
}

@InProceedings{10.1007/978-3-319-67262-5_15,
author="Baresi, Luciano
and Filgueira Mendon{\c{c}}a, Danilo
and Garriga, Martin",
editor="De Paoli, Flavio
and Schulte, Stefan
and Broch Johnsen, Einar",
title="Empowering Low-Latency Applications Through a Serverless Edge Computing Architecture",
booktitle="Service-Oriented and Cloud Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="196--210",
abstract="The exponential increase of the data generated by pervasive and mobile devices requires disrupting approaches for the realization of emerging mobile and IoT applications. Although cloud computing provides virtually unlimited computational resources, low-latency applications cannot afford the high latencies introduced by sending and retrieving data from/to the cloud. In this scenario, edge computing appears as a promising solution by bringing computation and data near to users and devices. However, the resource-finite nature of edge servers constrains the possibility of deploying full applications on them. To cope with these problems, we propose a serverless architecture at the edge, bringing a highly scalable, intelligent and cost-effective use of edge infrastructure's resources with minimal configuration and operation efforts. The feasibility of our approach is shown through an augmented reality use case for mobile devices, in which we offload computation and data intensive tasks from the devices to serverless functions at the edge, outperforming the cloud alternative up to 80{\%} in terms of throughput and latency.",
isbn="978-3-319-67262-5"
}

@Article{Becker2019,
author="Becker, Christian
and Julien, Christine
and Lalanda, Philippe
and Zambonelli, Franco",
title="Pervasive computing middleware: current trends and emerging challenges",
journal="CCF Transactions on Pervasive Computing and Interaction",
year="2019",
month="Feb",
day="19",
abstract="Driven by the increasing diffusion of embedded sensors and actuators, and more in general by ``Internet of Things'' (IoT) devices, pervasive computing is becoming a reality. Yet, most actual implementations of pervasive computing environments rely on rather centralized architectures and on middleware solutions that integrate only the minimal set of services to enable interoperabilty and data integration. In this article, after having overviewed the state of the art in the area of pervasive computing middleware, we discuss the many challenges that still have to be faced for pervasive computing middleware to be able to support elastic, easy to configure, easy to develop, safe, and ethically acceptable, pervasive computing services and applications.",
issn="2524-5228",
doi="10.1007/s42486-019-00005-2",
url="https://doi.org/10.1007/s42486-019-00005-2"
}

@InProceedings{10.1007/978-3-319-91764-1_16,
author="Bermbach, David
and Pallas, Frank
and P{\'e}rez, David Garc{\'i}a
and Plebani, Pierluigi
and Anderson, Maya
and Kat, Ronen
and Tai, Stefan",
editor="Braubach, Lars
and Murillo, Juan M.
and Kaviani, Nima
and Lama, Manuel
and Burgue{\~{n}}o, Loli
and Moha, Naouel
and Oriol, Marc",
title="A Research Perspective on Fog Computing",
booktitle="Service-Oriented Computing -- ICSOC 2017 Workshops",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="198--210",
abstract="State-of-the-art applications are typically deployed on top of cloud services which offer the illusion of infinite resources, elastic scalability, and a simple pay-per-use billing model. While this is very convenient for developers, it also comes with relatively high access latency for end users. Future application domains such as the Internet of Things, autonomous driving, or future 5G mobile apps, however, require low latency access which is typically achieved by moving computation towards the edge of the network. This natural extension of the cloud towards the edge is typically referred to as Fog Computing and has lately found a lot of attention. However, Fog Computing as a deployment platform has not yet found widespread adoption; this, we believe, could be helped through a consistent use of the service-oriented computing paradigm for fog infrastructure services. Based on this motivation, this paper describes the concept of Fog Computing in detail, discusses the main obstacles for Fog Computing adoption, and derives open research challenges.",
isbn="978-3-319-91764-1"
}

@InProceedings{10.1007/978-3-319-64203-1_26,
author="Bravo Ferreira, Jos{\'e}
and Cello, Marco
and Iglesias, Jes{\'u}s Omana",
editor="Rivera, Francisco F.
and Pena, Tom{\'a}s F.
and Cabaleiro, Jos{\'e} C.",
title="More Sharing, More Benefits? A Study of Library Sharing in Container-Based Infrastructures",
booktitle="Euro-Par 2017: Parallel Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="358--371",
abstract="Container-based infrastructures have surged in popularity, offering advantages in agility and scaling, while also presenting new challenges in resource utilization due to unnecessary library duplication. In this paper, we consider sharing libraries across containers, and study the impact of such a strategy on overall resource requirements, scheduling, and utilization. Our analysis and simulations suggest significant benefits arising from library sharing. Furthermore, a small fraction of libraries shared between any two containers, on average, is enough to reap most of the benefits, and even na{\"i}ve schedulers, such as a First Fit scheduler, succeed at doing so. We also propose a score maximization, mixed-integer linear-programming scheduler for handling bulk request arrivals (such as large jobs composed of many smaller tasks), which compares favorably against state-of-the-art schedulers in these scenarios.",
isbn="978-3-319-64203-1"
}

@InProceedings{10.1007/978-3-030-00470-5_30,
author="Bushouse, Micah
and Reeves, Douglas",
editor="Bailey, Michael
and Holz, Thorsten
and Stamatogiannakis, Manolis
and Ioannidis, Sotiris",
title="Furnace: Self-service Tenant VMI for the Cloud",
booktitle="Research in Attacks, Intrusions, and Defenses",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="647--669",
abstract="Although Virtual Machine Introspection (VMI) tools are increasingly capable, modern multi-tenant cloud providers are hesitant to expose the sensitive hypervisor APIs necessary for tenants to use them. Outside the cloud, VMI and virtualization-based security's adoption rates are rising and increasingly considered necessary to counter sophisticated threats. This paper introduces Furnace, an open source VMI framework that outperforms prior frameworks by satisfying both a cloud provider's expectation of security and a tenant's desire to run their own custom VMI tools underneath their cloud VMs. Furnace's flexibility and ease of use is demonstrated by porting four existing security and monitoring tools as Furnace VMI apps; these apps are shown to be resource efficient while executing up to 300x faster than those in previous VMI frameworks. Furnace's security properties are shown to protect against the actions of malicious tenant apps.",
isbn="978-3-030-00470-5"
}

@InProceedings{10.1007/978-3-319-94478-4_17,
author="Chen, Huan
and Zhang, Liang-Jie",
editor="Chen, Shiping
and Wang, Harry
and Zhang, Liang-Jie",
title="FBaaS: Functional Blockchain as a Service",
booktitle="Blockchain -- ICBC 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="243--250",
abstract="Serverless architecture has been gaining popularity in the last three years. Function as a Service (FaaS) is a concrete realization of the Serverless architecture and has several advantages and features. This paper proposes a new service model which is based on FaaS model, named FBaaS -- Functional Blockchain as a Service. Compared with Blockchain as a Service (BaaS), FBaaS has a lighter implementation of top-level business logics, which brings a number of advantages. Firstly, it could improve the operation speed of a blockchain. Secondly, the continuous advances in high robustness, high availability of the underlying FaaS network can be naturally adapted to the FBaaS because of its hierarchical architecture. Thirdly, FaaS implements higher level of abstraction of the logics that is much succinct. Moreover, this paper proposes an abstraction method in the realization of a business logic of consortium blockchain that could further improve the performance. In this paper, we also unfold the details of a concrete example network, which is the conference blockchain network for Services Conference Federation (SCF) 2018.",
isbn="978-3-319-94478-4"
}

@InProceedings{10.1007/978-3-319-67380-6_4,
author="Devos, Mathieu
and Masek, Pavel",
editor="Galinina, Olga
and Andreev, Sergey
and Balandin, Sergey
and Koucheryavy, Yevgeni",
title="Battery Monitoring Within Industry 4.0 Landscape: Solution as a Service (SaaS) for Industrial Power Unit Systems",
booktitle="Internet of Things, Smart Spaces, and Next Generation Networks and Systems",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="40--52",
abstract="The current globalization already faces the challenge of meeting the continuously growing demand for new consumer goods by simultaneously ensuring a sustainable evolution of human existence. The industrial value creation must be geared towards sustainability. In order to overcome this challenge, tightly coupling the production and its axiomatization processes is required in the paradigm of Industry 4.0. This technology bridges together a vast amount of new interconnected smart devices being mostly battery powered. Batteries are the heart of industrial motive power and electric energy storing solutions in the infrastructures of today. The charges related to the batteries are among the biggest cost (2.000--5.000 EUR per unit). Unfortunately, the batteries are not always treated properly and the badly managed ones lose their ability to store energy quickly. In this work, we present the developed modular Cloud solution utilizing Solution as a Service (SaaS) to monitor and manage industrial power unit systems. Modular approach is realized using simple miniature non-intrusive wireless sensors combined with cloud platform that provides the battery intelligence.",
isbn="978-3-319-67380-6"
}

@Inbook{Frischbier2010,
author="Frischbier, Sebastian
and Petrov, Ilia",
editor="Sachs, Kai
and Petrov, Ilia
and Guerrero, Pablo",
title="Aspects of Data-Intensive Cloud Computing",
bookTitle="From Active Data Management to Event-Based Systems and More: Papers in Honor of Alejandro Buchmann on the Occasion of His 60th Birthday",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="57--77",
abstract="The concept of Cloud Computing is by now at the peak of public attention and adoption. Driven by several economic and technological enablers, Cloud Computing is going to change the way we have to design, maintain and optimise large-scale data-intensive software systems in the future. Moving large-scale, data-intensive systems into the Cloud may not always be possible, but would solve many of today's typical problems. In this paper we focus on the opportunities and restrictions of current Cloud solutions regarding the data model of such software systems. We identify the technological issues coming along with this new paradigm and discuss the requirements to be met by Cloud solutions in order to provide a meaningful alternative to on-premise configurations.",
isbn="978-3-642-17226-7",
doi="10.1007/978-3-642-17226-7_4",
url="https://doi.org/10.1007/978-3-642-17226-7_4"
}

@InProceedings{10.1007/978-3-030-22397-7_9,
author="Gabbrielli, Maurizio
and Giallorenzo, Saverio
and Lanese, Ivan
and Montesi, Fabrizio
and Peressotti, Marco
and Zingaro, Stefano Pio",
editor="Riis Nielson, Hanne 
and Tuosto, Emilio",
title="No More, No Less",
booktitle="Coordination Models and Languages",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="148--157",
abstract="Serverless computing, also known as Functions-as-a-Service, is a recent paradigm aimed at simplifying the programming of cloud applications. The idea is that developers design applications in terms of functions, which are then deployed on a cloud infrastructure. The infrastructure takes care of executing the functions whenever requested by remote clients, dealing automatically with distribution and scaling with respect to inbound traffic.",
isbn="978-3-030-22397-7"
}

@InProceedings{10.1007/978-3-319-74781-1_15,
author="Garriga, Martin",
editor="Cerone, Antonio
and Roveri, Marco",
title="Towards a Taxonomy of Microservices Architectures",
booktitle="Software Engineering and Formal Methods",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="203--218",
abstract="The microservices architectural style is gaining more and more momentum for the development of applications as suites of small, autonomous, and conversational services, which are then easy to understand, deploy and scale. However, the proliferation of approaches leveraging microservices calls for a systematic way of analyzing and assessing them as a completely new ecosystem: the first cloud-native architectural style. This paper defines a preliminary analysis framework in the form of a taxonomy of concepts, encompassing the whole microservices lifecycle, as well as organizational aspects. This framework is necessary to enable effective exploration, understanding, assessing, comparing, and selecting microservice-based models, languages, techniques, platforms, and tools. Then, we analyze state of the art approaches related to microservices using this taxonomy to provide a holistic perspective of available solutions.",
isbn="978-3-319-74781-1"
}

@InProceedings{10.1007/978-3-030-13342-9_15,
author="Horovitz, Shay
and Amos, Roei
and Baruch, Ohad
and Cohen, Tomer
and Oyar, Tal
and Deri, Afik",
editor="Coppola, Massimo
and Carlini, Emanuele
and D'Agostino, Daniele
and Altmann, J{\"o}rn
and Ba{\~{n}}ares, Jos{\'e} {\'A}ngel",
title="FaaStest - Machine Learning Based Cost and Performance FaaS Optimization",
booktitle="Economics of Grids, Clouds, Systems, and Services",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="171--186",
abstract="With the emergence of Function-as-a-Service (FaaS) in the cloud, pay-per-use pricing models became available along with the traditional fixed price model for VMs and increased the complexity of selecting the optimal platform for a given service. We present FaaStest - an autonomous solution for cost and performance optimization of FaaS services by taking a hybrid approach - learning the behavioral patterns of the service and dynamically selecting the optimal platform. Moreover, we combine a prediction based solution for reducing cold starts of FaaS services. Experiments present a reduction of over 50{\%} in cost and over 90{\%} in response time for FaaS calls.",
isbn="978-3-030-13342-9"
}

@InProceedings{10.1007/978-3-319-69035-3_17,
author="HoseinyFarahabady, MohammadReza
and Lee, Young Choon
and Zomaya, Albert Y.
and Tari, Zahir",
editor="Maximilien, Michael
and Vallecillo, Antonio
and Wang, Jianmin
and Oriol, Marc",
title="A QoS-Aware Resource Allocation Controller for Function as a Service (FaaS) Platform",
booktitle="Service-Oriented Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="241--255",
abstract="Function as a Service (FaaS) is a recent event-driven serverless paradigm that allows enterprises to build their applications in a fault tolerant distributed manner. Having been considered as an attractive replacement of traditional Service Oriented Architecture (SOA), the FaaS platform leverages the management of massive data sets or the handling of event streams. However, the realization of such leverage is largely dependent on the effective exploitation of FaaS elasticity/scalability.",
isbn="978-3-319-69035-3"
}

@InProceedings{10.1007/978-3-030-03673-7_4,
author="Ivanov, Vitalii
and Smolander, Kari",
editor="Kuhrmann, Marco
and Schneider, Kurt
and Pfahl, Dietmar
and Amasaki, Sousuke
and Ciolkowski, Marcus
and Hebig, Regina
and Tell, Paolo
and Kl{\"u}nder, Jil
and K{\"u}pper, Steffen",
title="Implementation of a DevOps Pipeline for Serverless Applications",
booktitle="Product-Focused Software Process Improvement",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="48--64",
abstract="Context: The term ``serverless'' defines applications that use elements of Function as a Service or Backend as a Service cloud models in their architectures. Serverless promises infrastructure and operations cost reduction, faster software development, and automatic application scalability. Although many practitioners agree that Serverless simplifies operations part of DevOps, it still requires a new approach to automation practices because of the differences in its design and development workflow. Goal: The goal of this paper is to explore how Serverless affects DevOps practices and demonstrate a DevOps pipeline implementation for a Serverless case project. Method: As the method, we use the design science research, where the resulting artefact is a release and monitoring pipeline designed and implemented according to the requirements of the case organization. Results: The result of the study is an automated DevOps pipeline with an implementation of Continuous Integration, Continuous Delivery and Monitoring practices as required by the Serverless approach of the case project. Conclusions: The outcome shows how strongly the Serverless approach affects some automation practices such as test execution, deployment and monitoring of the application. In total, 18 out of 27 implemented practices were influenced by the Serverless-specific features of the project.",
isbn="978-3-030-03673-7"
}

@InProceedings{10.1007/978-3-319-69035-3_51,
author="Jiang, Qingye
and Lee, Young Choon
and Zomaya, Albert Y.",
editor="Maximilien, Michael
and Vallecillo, Antonio
and Wang, Jianmin
and Oriol, Marc",
title="Serverless Execution of Scientific Workflows",
booktitle="Service-Oriented Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="706--721",
abstract="In this paper, we present a serverless workflow execution system (DEWE v3{\$}{\$}^{\{}1{\}}{\$}{\$}) with Function-as-a-Service (FaaS aka serverless computing) as the target execution environment. DEWE v3 is designed to address problems of (1) execution of large-scale scientific workflows and (2) resource underutilization. At its core is our novel hybrid (FaaS and dedicated/local clusters) job dispatching approach taking into account resource consumption patterns of different phases of workflow execution. In particular, the hybrid approach deals with the maximum execution duration limit, memory limit, and storage space limit. DEWE v3 significantly reduces the efforts needed to execute large-scale scientific workflow applications on public clouds. We have evaluated DEWE v3 on both AWS Lambda and Google Cloud Functions and demonstrate that FaaS offers an ideal solution for scientific workflows with complex precedence constraints. In our large-scale evaluations, the hybrid execution model surpasses the performance of the traditional cluster execution model with significantly less execution cost.",
isbn="978-3-319-69035-3"
}

@Inbook{Kousalya2017,
author="Kousalya, G.
and Balakrishnan, P.
and Pethuru Raj, C.",
title="Demystifying the Traits of Software-Defined Cloud Environments (SDCEs)",
bookTitle="Automated Workflow Scheduling in Self-Adaptive Clouds: Concepts, Algorithms and Methods",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="23--53",
abstract="Definitely the cloud journey is on the fast track. The cloud idea got originated and started to thrive from the days of server virtualization. Server machines are being virtualized in order to have multiple virtual machines, which are provisioned dynamically and kept in ready and steady state to deliver sufficient resources (compute, storage, and network) for optimally running any software application. That is, a physical machine can be empowered to run multiple and different applications through the aspect of virtualization. Resultantly, the utilization of expensive compute machines is steadily going up.",
isbn="978-3-319-56982-6",
doi="10.1007/978-3-319-56982-6_2",
url="https://doi.org/10.1007/978-3-319-56982-6_2"
}

@InProceedings{10.1007/978-3-319-69035-3_48,
author="Kuhlenkamp, J{\"o}rn
and Klems, Markus",
editor="Maximilien, Michael
and Vallecillo, Antonio
and Wang, Jianmin
and Oriol, Marc",
title="Costradamus: A Cost-Tracing System for Cloud-Based Software Services",
booktitle="Service-Oriented Computing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="657--672",
abstract="Cloud providers offer a range of fully managed infrastructure services that enable a ``serverless'' architecture and development paradigm. Following this paradigm, software services can be built on compositions of cloud infrastructure services that offer fine-granular pay-per-use pricing models. While this development and deployment approach simplifies service development and management, it remains an open challenge to make use of fine-granular pricing models for improving cost transparency and reducing cost of service operations. As a solution, we present Costradamus, a cost-tracing system that implements a generic cost model and three different tracing approaches. With Costradamus, we can derive cost and performance information per API operation. We evaluate our approach and system in a smart grid context and discuss unexpected performance and deployment cost tradeoffs.",
isbn="978-3-319-69035-3"
}

@Inbook{Lebanon2018,
author="Lebanon, Guy
and El-Geish, Mohamed",
title="Thoughts on System Design for Big Data",
bookTitle="Computing with Data: An Introduction to the Data Industry",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="495--541",
abstract="In the context of computing with data, what exactly is a system? Generally speaking, a system is an aggregation of computing components (and the links between them) that collectively provide a solution to a problem. System design covers choices that system designers make regarding such components: hardware (e.g., servers, networks, sensors, etc.); software (e.g., operating systems, cluster managers, applications, etc.); data (e.g., collection, retention, processing, etc.); and other components that vary based on the nature of each solution. There's no free lunch in system design and no silver bullet; instead, there are patterns that can jumpstart a solution; and for the most part, there will always be tradeoffs. Skilled system designers learn how to deal with novel problems and ambiguity; one of the skills they practice is decomposing a complex problem into more manageable subproblems that look analogous to ones that can be solved using known patterns, then connect those components together to solve the complex problem. In this chapter, we put on our designer hats and explore various aspects of system design in practice by creating a hypothetical big-data solution: a productivity bot.",
isbn="978-3-319-98149-9",
doi="10.1007/978-3-319-98149-9_14",
url="https://doi.org/10.1007/978-3-319-98149-9_14"
}

@InProceedings{10.1007/978-3-319-74433-9_6,
author="Lehv{\"a}, Jyri
and M{\"a}kitalo, Niko
and Mikkonen, Tommi",
editor="Garrig{\'o}s, Irene
and Wimmer, Manuel",
title="Case Study: Building a Serverless Messenger Chatbot",
booktitle="Current Trends in Web Engineering",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="75--86",
abstract="Major chat platforms, such as Facebook Messenger, have recently added support for chatbots, thus making chatbots more accessible for the end users. This paper presents a case study on building and designing a Messenger chatbot for a media company. The chatbot uses a Serverless Microservice architecture which was implemented using Amazon Web Services (AWS) including API Gateway, Lambda, DynamoDB, SNS and CloudWatch. The paper presents the architecture and reports the findings regarding the design and the final implementation. These findings are also compared to other recent studies around the same emerging topic.",
isbn="978-3-319-74433-9"
}

@InProceedings{10.1007/978-3-319-75178-8_34,
author="Malawski, Maciej
and Figiela, Kamil
and Gajek, Adam
and Zima, Adam",
editor="Heras, Dora B.
and Boug{\'e}, Luc
and Mencagli, Gabriele
and Jeannot, Emmanuel
and Sakellariou, Rizos
and Badia, Rosa M.
and Barbosa, Jorge G.
and Ricci, Laura
and Scott, Stephen L.
and Lankes, Stefan
and Weidendorfer, Josef",
title="Benchmarking Heterogeneous Cloud Functions",
booktitle="Euro-Par 2017: Parallel Processing Workshops",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="415--426",
abstract="Cloud Functions, often called Function-as-a-Service (FaaS), pioneered by AWS Lambda, are an increasingly popular method of running distributed applications. As in other cloud offerings, cloud functions are heterogeneous, due to different underlying hardware, runtime systems, as well as resource management and billing models. In this paper, we focus on performance evaluation of cloud functions, taking into account heterogeneity aspects. We developed a cloud function benchmarking framework, consisting of one suite based on Serverless Framework, and one based on HyperFlow. We deployed the CPU-intensive benchmarks: Mersenne Twister and Linpack, and evaluated all the major cloud function providers: AWS Lambda, Azure Functions, Google Cloud Functions and IBM OpenWhisk. We make our results available online and continuously updated. We report on the initial results of the performance evaluation and we discuss the discovered insights on the resource allocation policies.",
isbn="978-3-319-75178-8"
}

@Article{Manner2019,
author="Manner, Johannes
and Kolb, Stefan
and Wirtz, Guido",
title="Troubleshooting Serverless functions: a combined monitoring and debugging approach",
journal="SICS Software-Intensive Cyber-Physical Systems",
year="2019",
month="Feb",
day="06",
abstract="Today, Serverless computing gathers pace and attention in the cloud computing area. The abstraction of operational tasks combined with the auto-scaling property are convincing reasons to adapt this new cloud paradigm. Building applications in a Serverless style via cloud functions is challenging due to the fine-grained architecture and the tighter coupling to back end services. Increased complexity, loss of control over software layers and the large number of participating functions and back end services complicate the task of finding the cause of a faulty execution. A tedious but widespread strategy is the manual analysis of log data. In this paper, we present a semi-automated troubleshooting process to improve fault detection and resolution for Serverless functions. Log data is the vehicle to enable a posteriori analysis. The process steps of our concept enhance the log quality, detect failed executions automatically, and generate test skeletons based on the information provided in the log data. Ultimately, this leads to an increased test coverage, a better regression testing and more robust functions. Developers can trigger this process asynchronously and work with their accustomed tools. We also present a prototype SeMoDe to validate our approach for Serverless functions implemented in Java and deployed to AWS Lambda.",
issn="2524-8529",
doi="10.1007/s00450-019-00398-6",
url="https://doi.org/10.1007/s00450-019-00398-6"
}

@InProceedings{10.1007/978-3-319-99253-2_32,
author="Merelo Guerv{\'o}s, Juan J.
and Garc{\'i}a-Valdez, J. Mario",
editor="Auger, Anne
and Fonseca, Carlos M.
and Louren{\c{c}}o, Nuno
and Machado, Penousal
and Paquete, Lu{\'i}s
and Whitley, Darrell",
title="Introducing an Event-Based Architecture for Concurrent and Distributed Evolutionary Algorithms",
booktitle="Parallel Problem Solving from Nature -- PPSN XV",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="399--410",
abstract="Cloud-native applications add a layer of abstraction to the underlying distributed computing system, defining a high-level, self-scaling and self-managed architecture of different microservices linked by a messaging bus. Creating new algorithms that tap these architectural patterns and at the same time employ distributed resources efficiently is a challenge we will be taking up in this paper. We introduce KafkEO, a cloud-native evolutionary algorithms framework that is prepared to work with different implementations of evolutionary algorithms and other population-based metaheuristics by using micro-populations and stateless services as the main building blocks; KafkEO is an attempt to map the traditional evolutionary algorithm to this new cloud-native format. As far as we know, this is the first architecture of this kind that has been published and tested, and is free software and vendor-independent, based on OpenWhisk and Kafka. This paper presents a proof of concept, examines its cost, and tests the impact on the algorithm of the design around cloud-native and asynchronous system by comparing it on the well known BBOB benchmarks with other pool-based architectures, with which it has a remarkable functional resemblance. KafkEO results are quite competitive with similar architectures.",
isbn="978-3-319-99253-2"
}
@Inbook{Nastic2018,
author="Nastic, Stefan
and Dustdar, Schahram",
editor="Gruhn, Volker
and Striemer, R{\"u}diger",
title="Towards Deviceless Edge Computing: Challenges, Design Aspects, and Models for Serverless Paradigm at the Edge",
bookTitle="The Essence of Software Engineering",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="121--136",
abstract="The serverless paradigm has been rapidly adopted by developers of cloud-native applications, mainly because it relieves them from the burden of provisioning, scaling, and operating the underlying infrastructure. In this chapter, we propose a novel computing paradigm---Deviceless Edge Computing--- that extends the serverless paradigm to the edge of the network, enabling IoT and Edge devices, such as gateways and micro clouds, to be seamlessly integrated as application execution infrastructure. We propose a reference architecture for the Deviceless Edge Computing. We also analyze the main requirements and challenges to realize this novel computing paradigm from two main points of view: (1) required support for application development, in terms of programming models, and (2) required runtime support for deviceless applications, in terms of main deviceless platform mechanisms. Finally, we show how our existing work in the area of Edge Computing and IoT serves as starting point and as one of main enablers for realizing the emerging Deviceless Edge Computing.",
isbn="978-3-319-73897-0",
doi="10.1007/978-3-319-73897-0_8",
url="https://doi.org/10.1007/978-3-319-73897-0_8"
}

@InProceedings{10.1007/978-3-030-01701-9_25,
author="Qiang, Weizhong
and Dong, Zezhao
and Jin, Hai",
editor="Beyah, Raheem
and Chang, Bing
and Li, Yingjiu
and Zhu, Sencun",
title="Se-Lambda: Securing Privacy-Sensitive Serverless Applications Using SGX Enclave",
booktitle="Security and Privacy in Communication Networks",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="451--470",
abstract="Serverless computing is an emerging trend in the cloud, which represents a new paradigm for deploying applications and services. In the serverless computing framework, cloud users can deploy arbitrary code and process data on the service runtime. However, as neither cloud users nor cloud providers are trustworthy, serverless computing platform suffers from trust issues caused by both sides. In this paper, we propose a new serverless computing framework called Se-Lambda, which protects the API gateway by using SGX enclave and the service runtime by leveraging a two-way sandbox that combines SGX enclave and WebAssembly sandboxed environment. In the proposed service runtime, users' untrusted code is confined by WebAssembly sandboxed environment, while SGX enclave prevents malicious cloud providers from stealing users' privacy-sensitive data. In addition, we implement a privilege monitoring mechanism in SGX enclave to manage the access control of function modules from users. We implement the prototype of Se-Lambda based on the open source project OpenLambda. The experimental results show that the Se-Lambda imposes a low performance penalty, while buying a significantly increased level of security.",
isbn="978-3-030-01701-9"
}

@Inbook{Ramachandran2018,
author="Ramachandran, Muthu",
editor="Mahmood, Zaigham",
title="SEF-SCC: Software Engineering Framework for Service and Cloud Computing",
bookTitle="Fog Computing: Concepts, Frameworks and Technologies",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="227--248",
abstract="Service computingService computingand cloud computing have emerged to address the need for more flexible and cost-efficient computing systems where software is delivered as a service. To make this more resilient and reliable, we need to adopt software engineering (SE) principles and best practices that have existed for the last 40 years or so. Therefore, this chapter proposes a Software EngineeringSoftware EngineeringFramework for Service and Cloud ComputingCloud Computing(SEF-SCC) to address the need for a systematic approach to design and develop robust, resilient, and reusable services. This chapter presents SEF-SCC methods, techniques, and a systematic engineering process supporting the development of service-oriented software systems and software as a service paradigms. SEF-SCC has been successfully validated for the past 10 years based on a large-scale case study on British Energy Power and Energy Trading (BEPETBEPET). Ideas and concepts suggested in this chapter are equally applicable to all distributed computing environments including Fog and Edge Computing paradigms.",
isbn="978-3-319-94890-4",
doi="10.1007/978-3-319-94890-4_11",
url="https://doi.org/10.1007/978-3-319-94890-4_11"
}

@InProceedings{10.1007/978-3-319-73353-1_11,
author="Spillner, Josef
and Mateos, Cristian
and Monge, David A.",
editor="Mocskos, Esteban
and Nesmachnow, Sergio",
title="FaaSter, Better, Cheaper: The Prospect of Serverless Scientific Computing and HPC",
booktitle="High Performance Computing",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="154--168",
abstract="The adoption of cloud computing facilities and programming models differs vastly between different application domains. Scalable web applications, low-latency mobile backends and on-demand provisioned databases are typical cases for which cloud services on the platform or infrastructure level exist and are convincing when considering technical and economical arguments. Applications with specific processing demands, including high-performance computing, high-throughput computing and certain flavours of scientific computing, have historically required special configurations such as compute- or memory-optimised virtual machine instances. With the rise of function-level compute instances through Function-as-a-Service (FaaS) models, the fitness of generic configurations needs to be re-evaluated for these applications. We analyse several demanding computing tasks with regards to how FaaS models compare against conventional monolithic algorithm execution. Beside the comparison, we contribute a refined FaaSification process for legacy software and provide a roadmap for future work.",
isbn="978-3-319-73353-1"
}

@InProceedings{10.1007/978-3-319-72125-5_16,
author="Tai, Stefan",
editor="Lazovik, Alexander
and Schulte, Stefan",
title="Continuous, Trustless, and Fair: Changing Priorities in Services Computing",
booktitle="Advances in Service-Oriented and Cloud Computing",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="205--210",
abstract="Services computing research and practice traditionally has focused on the objectives of business alignment, software systems interoperability and on leveraging the Web as a compute platform. Corresponding technology solution stacks and architectural styles have been promoted. Today, and probably for the next decade to come, different objectives are replacing these original ones and, correspondingly, different solution stacks and architectural styles are emerging. Most notably, challenges such as frequent delivery of service systems, decentralization and business disintermediation, and ``socially aligned'' service systems lead us to continuous computing, trustless computing, and fair computing -- three major trends that we expect to become the driving force behind next-generation service systems. In this paper, we discuss these trends and identify major research directions to deliver on these changing priorities.",
isbn="978-3-319-72125-5"
}

@InProceedings{10.1007/978-3-030-06010-7_4,
author="Toepke, Samuel Lee",
editor="Ragia, Lemonia
and Laurini, Robert
and Rocha, Jorge Gustavo",
title="Implications of Data Density and Length of Collection Period for Population Estimations Using Social Media Data",
booktitle="Geographical Information Systems Theory, Applications and Management",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="57--69",
abstract="When programmatically utilizing public APIs provided by social media services, it is possible to attain a large volume of volunteered geographic information. Geospatially enabled data from Twitter, Instagram, Panaramio, etc. can be used to create high-resolution estimations of human movements over time, with volume of the data being of critical importance. This investigation extends previous work, showing the effects of artificial data removal, and generated error; though using over twice as much collected data, attained using an enterprise cloud solution, over a span of thirteen months instead of five.",
isbn="978-3-030-06010-7"
}

@Article{Villamizar2017,
author="Villamizar, Mario
and Garc{\'e}s, Oscar
and Ochoa, Lina
and Castro, Harold
and Salamanca, Lorena
and Verano, Mauricio
and Casallas, Rubby
and Gil, Santiago
and Valencia, Carlos
and Zambrano, Angee
and Lang, Mery",
title="Cost comparison of running web applications in the cloud using monolithic, microservice, and AWS Lambda architectures",
journal="Service Oriented Computing and Applications",
year="2017",
month="Jun",
day="01",
volume="11",
number="2",
pages="233--247",
abstract="Large Internet companies like Amazon, Netflix, and LinkedIn are using the microservice architecture pattern to deploy large applications in the cloud as a set of small services that can be independently developed, tested, deployed, scaled, operated, and upgraded. However, aside from gaining agility, independent development, and scalability, how microservices affect the infrastructure costs is a major evaluation topic for companies adopting this pattern. This paper presents a cost comparison of a web application developed and deployed using the same scalable scenarios with three different approaches: 1) a monolithic architecture, 2) a microservice architecture operated by the cloud customer, and 3) a microservice architecture operated by the cloud provider. Test results show that microservices can help reduce infrastructure costs in comparison with standard monolithic architectures. Moreover, the use of services specifically designed to deploy and scale microservices, such as AWS Lambda, reduces infrastructure costs by 70{\%} or more, and unlike microservices operated by cloud customers, these specialized services help to guarantee the same performance and response times as the number of users increases. Lastly, we also describe the challenges we faced while implementing and deploying microservice applications, and include a discussion on how to replicate the results on other cloud providers.",
issn="1863-2394",
doi="10.1007/s11761-017-0208-y",
url="https://doi.org/10.1007/s11761-017-0208-y"
}
@InProceedings{10.1007/978-3-030-04284-4_10,
author="Vogelgesang, Christian
and Spieldenner, Torsten
and Schubotz, Ren{\'e}",
editor="Ichise, Ryutaro
and Lecue, Freddy
and Kawamura, Takahiro
and Zhao, Dongyan
and Muggleton, Stephen
and Kozaki, Kouji",
title="SPARQ{\$}{\$}{\backslash}lambda {\$}{\$}: A Functional Perspective on Linked Data Services",
booktitle="Semantic Technology",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="136--152",
abstract="With more and more applications providing semantic data to improve interoperability, the amount of available RDF datasets is constantly increasing. The SPARQL query language is a W3C recommendation to provide query capabilities on such RDF datasets. Data integration from different RDF sources is up to now mostly task of RDF consuming clients. However, from a functional perspective, data integration boils down to a function application that consumes input data as parameters, and based on these, produces a new set of data as output. Following this notion, we introduce SPARQ{\$}{\$}{\backslash}lambda {\$}{\$}, an extension to the SPARQL 1.1 query language. SPARQ{\$}{\$}{\backslash}lambda {\$}{\$}enables dynamic injection of RDF datasets during evaluation of the query, and by this lifts SPARQL to a tool to write templates for RDF producing functions, an important step to reduce the effort to write SPARQL queries that work on data from various sources. SPARQ{\$}{\$}{\backslash}lambda {\$}{\$}is moreover suitable to directly translate to an RDF described Web service interface, which allows to lift integration of data and re-provisioning of integrated results from clients to cloud environments, and by this solving the bottleneck of RDF data integration on client side.",
isbn="978-3-030-04284-4"
}

@InProceedings{10.1007/978-3-319-94295-7_18,
author="Zhou, Huan
and Hu, Yang
and Su, Jinshu
and de Laat, Cees
and Zhao, Zhiming",
editor="Luo, Min
and Zhang, Liang-Jie",
title="CloudsStorm: An Application-Driven Framework to Enhance the Programmability and Controllability of Cloud Virtual Infrastructures",
booktitle="Cloud Computing -- CLOUD 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="265--280",
abstract="Most current IaaS (Infrastructure-as-a-Service) clouds provide dedicated virtual infrastructure resources to cloud applications with only limited programmability and controllability, which enlarges the management gap between infrastructures and applications. Traditional DevOps (development and operations) approaches are not suitable in today's cloud environments, because of the slow, manual and error-prone collaboration between developers and operations personnel. It is essential to involve the operation into the cloud application development phase, which needs to make the infrastructure able to be controlled by the application directly. Moreover, each of these cloud providers offers their own set of APIs to access the resources. It causes the vendor lock-in problem for the application when managing its infrastructure across federated clouds or multiple data centers. To mitigate this gap, we have designed CloudsStorm, an application-driven DevOps framework that allows the application directly program and control its infrastructure. In particular, it provides multi-level programmability and controllability according to the applications' specifications. We evaluate it by comparing its functionality to other proposed solutions. Moreover, we implement an extensible TSV-Engine, which is the core component of CloudsStorm for managing infrastructures. It is the first to be able to provision a networked infrastructure among public clouds. At last, we conduct a set of experiments on actual clouds and compare with other related DevOps tools. The experimental results demonstrate our solution is efficient and outperforms others.",
isbn="978-3-319-94295-7"
}

@InProceedings{10.1007/978-3-319-77028-4_45,
author="Zieba, Daniela
and Jenkins, Wren
and Galloway, Michael
and Houle, Jean-Luc",
editor="Latifi, Shahram",
title="Taking a Steppe Towards Optimizing Note-Taking Software by Creation of a Note Classification Algorithm",
booktitle="Information Technology - New Generations",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="333--341",
abstract="Note-taking software often far surpasses its paper-and-pencil counterpart when measured in metrics such as availability and reliability. However, there is ample opportunity relating to the analysis and organization of notes in structures often called folders, notebooks, or projects within various software. ShovelWare is a project designed for an ongoing field research project analyzing the Bronze and Iron Ages of Mongolia. Accessible through a web interface and cross-platform mobile application, it is a replacement for manual data collection on paper and excessive, error-ridden input into digital spreadsheets. We propose a machine learning algorithm that classifies notes using a variety of metrics, sorting them into graph structures to provide initial insights into the similarity of field notes. As a result, ShovelWare will allow archaeologists to more quickly and cleanly view and share their data. The algorithm, as well as the note-taking structure, are planned with hopes of scalability and applicability into more disciplines.",
isbn="978-3-319-77028-4"
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: saveOrderConfig:specified;author;false;abstract;false;abstract;false;}
